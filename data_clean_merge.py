# -*- coding: utf-8 -*-
"""data_clean_merge.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R1sZStAepEDA_ldwBuzfof7ANsIv1Nnf
"""

pip install pandas fuzzywuzzy python-Levenshtein

import pandas as pd
from fuzzywuzzy import process

# Load datasets
df_internal = pd.read_csv("/content/internal_inventory (3).csv")
df_scraped = pd.read_csv("/content/amazon_scraped_mock_data_100000.csv")

df_internal.info()
df_scraped.info()

# Step 1: Add Stock Status to internal inventory
def stock_status(row):
    if row['Stock'] < row['Reorder_Level']:
        return "Understock"
    elif row['Stock'] > 2 * row['Reorder_Level']:
        return "Overstock"
    else:
        return "Optimum"

df_internal["Stock_Status"] = df_internal.apply(stock_status, axis=1)

# Step 2: Clean scraped data
df_scraped["Price"] = pd.to_numeric(df_scraped["Price"], errors='coerce')
df_scraped["Rating"] = pd.to_numeric(df_scraped["Rating"], errors='coerce')
df_scraped["Reviews"] = pd.to_numeric(df_scraped["Reviews"], errors='coerce')
print(df_scraped.columns)
df_scraped.dropna(subset=["Scraped_Title"], inplace=True)

# prompt: to show table info

df_internal.info()
df_scraped.info()

# Match Products Using Fuzzy Matching
def match_product(search_item, item_names):
    match, score = process.extractOne(search_item, item_names)
    return match if score >= 80 else None

df_scraped["Matched_Item"] = df_scraped["Search_Item"].apply(
    lambda x: match_product(x, df_internal["Item_Name"].tolist())
)

merged_df = pd.merge(df_internal, df_scraped, left_on="Item_Name", right_on="Matched_Item", how="left")

merged_df.info()
df_scraped.info()

import os

# Create the 'data' directory if it doesn't exist
os.makedirs("data", exist_ok=True)

# Now you can save your dataframes to CSV files in the 'data' directory
df_internal.to_csv("data/inventory_cleaned.csv", index=False)
df_scraped.to_csv("data/amazon_scraped_cleaned.csv", index=False)
merged_df.to_csv("data/inventory_merged.csv", index=False)

# prompt: to show
df_scraped